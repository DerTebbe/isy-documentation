= Detailkonzept Service: Inhalt
include::{isy-dokumentvorlagen}/docs/common/isyfact-attributes.adoc[]

// tag::inhalt[]
[[namenskonventionen]]
== Namenskonventionen

Die Service-URLs der HTTP-Invoker-Schnittstellen müssen einheitlich aufgebaut sein.
Hierzu werden im Dokument <<IsyFactNamenskonventionen>> einheitliche Vorgaben definiert.

[[aufgaben-der-service-logik]]
== Aufgaben der Service-Logik

Die Service-Logik hat die folgenden Aufgaben:

*Transformation:* Bei einem Service-Aufruf müssen die Transportobjekte der Service-Schnittstelle in passende Objekte des Anwendungskerns umgewandelt werden.
Außerdem muss das Ergebnis des Anwendungskerns wieder in ein Transportobjekt der Service-Schnittstelle umgewandelt werden.

*Exception-Behandlung:* Tritt bei der Verarbeitung eines Service-Aufrufs im Anwendungskern oder in der Komponente "Service" eine Exception auf, so muss diese Exception in eine Exception der Service-Schnittstelle umgewandelt werden.

*Autorisierung:* Für einen Service-Aufruf muss eine Anwendung überprüfen, ob der Aufrufer autorisiert ist die Service-Operation auszuführen.

*Logging:* Die Komponente muss die Korrelation-ID in den Logging-Kontext einfügen.

[[aufbau-der-service-logik]]
== Aufbau der Service-Logik

Der Aufbau der Service-Logik ist in <<image-AufbauServLogik>> dargestellt.

:desc-image-AufbauServLogik: Aufbau Service-Logik
[id="image-AufbauServLogik",reftext="{figure-caption} {counter:figures}"]
.{desc-image-AufbauServLogik}
image::AufbauServLogik.png[align="center",width=80%,pdfwidth=80%]

Eine Service-Schnittstelle wird durch eine Fachanwendung entsprechend der Referenzarchitektur in Form einer
HTTP-Invoker-Schnittstelle angeboten.
Zum Aufruf dieser HTTP-Invoker-Schnittstelle definiert die Fachanwendung eine JAR-Datei, die die `RemoteBean` definiert und alle direkt oder indirekt verwendeten Transportobjekte der `RemoteBean`. Die JAR-Datei hat typischerweise
den Namen `<Anwendungsname>-httpinvoker-sst-<servicename>-vx.y-z.jar`.

NOTE: Als `RemoteBean` wird das Java-Interface bezeichnet, welches die Service-Schnittstelle definiert. Mit diesem Interface wird durch die passende Spring-Konfiguration in der Fachanwendung die  HTTP-Invoker-Schnittstelle definiert.

Jeder Methode der RemoteBean wird eine Instanz der Klasse `AufrufKontextTo` übergeben.
Diese Klasse ist in der Bibliothek `isy-serviceapi-sst` definiert.
Durch die Klasse werden jeder Methode der internen Service-Schnittstelle die Login-Daten (Benutzer,
Behörde, Passwort), die Rollen und die Correlation-ID übergeben.

Im Wesentlichen besteht die Service-Logik aus zwei Klassen, die im folgenden näher beleuchtet werden.

=== Aufbau der Exception-Fassade

Die Exception-Fassade ist verantwortlich für die Umwandlung der durch den Anwendungskern oder die Service-Logik geworfenen Exceptions in Exceptions der Service-Schnittstelle.
Hierzu implementiert die Exception-Fassade das Remote-Bean-Interface der Service-Schnittstelle und definiert in jeder Methode einen try-catch-Block, der alle Fehler des Anwendungskerns abfängt und in Fehler der Service-Schnittstelle umwandelt.

In <<listing-BSPExceptionFassade>> ist ein Beispiel für eine Exception-Fassade einer Fachanwendung angegeben.
Die Service-Operationen sind in diesem Fall die Methoden des Interfaces `BeispielRemoteBean`.
Konkret handelt es sich lediglich um die Service-Operation `holeBeispielAnfrage`.
Die Service-Operation ist mit der Annotation `@StelltLoggingKontextBereit` versehen, die eine mit dem `AufrufKontext` übergebene Korrelations-ID im Logging-Kontext registriert und diesen beim Verlassen der Methode wieder aufräumt.

NOTE: Falls im AufrufKontext keine Korrelations-ID vorhanden ist, so erzeugt die Annotation eine neue Korrelations-ID.

Es ist wichtig den Logging-Kontext zu setzen, bevor die Exception-Fassade aktiv wird.
Die Implementierung der Service-Operation reicht den Methodenaufruf an die implementierende Klasse (`BeispielService`) weiter, fängt auftretende Fehler jedoch über einen `try`-`catch`-Block ab.
Der `try`-`catch`-Block unterscheidet zwischen Exceptions der Datenbankzugriffsschicht (`DataAccessException`) und allen anderen Exceptions (`Throwable`), um einen passenden Fehlertext in die Log-Dateien zu schreiben.

:desc-listing-BSPExceptionFassade: Beispiel für eine Exception-Fassade
[id="listing-BSPExceptionFassade",reftext="{listing-caption} {counter:listings }"]
.{desc-listing-BSPExceptionFassade}
[source,java]
----
public class BeispielExceptionFassade implements BeispielRemoteBean
{
    private static final IsyLoggerStandard logger = ...;
    private BeispielService beispielService;
    ...
    @StelltLoggingKontextBereit
    public BeispielHolenAntwortTo holeBeispielAnfrage(AufrufKontextTo kontext, BeispielHolenAnfrageTo anfrage) throws BeispielTechnicalToException {
        try {
            return beispielService.holeBeispielAnfrage(kontext,anfrage);
        } catch (DataAccessException e) {
            logger.error("Fehler bei Transaktion", e);
            throw new BeispielTechnicalToException(...);
        } catch (Throwable t) {
            logger.error("...", t);
             throw new BeispielTechnicalToException(...);
        }
    }
    ...
}
----

=== Aufbau der Service-Fassade

Die Service-Fassade übernimmt die restlichen Aufgaben der Service-Logik:

* Sie transformiert die Transportobjekte der Service-Schnittstelle in Objekte des Anwendungskerns und umgekehrt.
Hierzu wird in der Regel ein Bean Mapper verwendet.
Falls die Transformation kompliziert ist, kann sie auch vollständig programmiert werden.
Hierbei sind Kosten und Nutzen genau abzuwägen.
* Sie führt gegebenenfalls die Autorisierung des Aufrufs aus.
Hierzu verwendet sie den Berechtigungsmanager (siehe <<NutzungsvorgabenSicherheit>>).

In <<listing-BSPServiceFassade>> ist ein Beispiel für eine Service-Fassade angegeben.
Die Implementierung der Service-Fassade erfolgt hier analog zur Implementierung der Exception-Fassade.
Die nach außen angebotene Service-Operation (`holeBeispielAnfrage`) wird jedoch nicht 1:1 an die implementierende Klasse weitergeleitet, da sich die Parameter und der Rückgabewert des Aufrufs unterscheiden.
Nach außen hin werden Transportobjekte angeboten.
Intern arbeitet die Anwendung mit ihren eigenen Entitäten.
Diese können sich von den nach außen hin angebotenen Transportobjekten unterscheiden, z.B. weil sie zusätzliche Attribute enthalten, einzelne Attribute anders benennen oder die Daten in irgendeiner Form anders repräsentieren als die Transportobjekte.

In der Service-Fassade erfolgt auch die Autorisierung eines Zugriffs auf eine Servicemethode.
Voraussetzung für die Autorisierung ist die Auswertung des mitgelieferten AufrufKontextes über die
Annotation `@StelltAufrufKontextBereit` an der Servicemethode.
Anschließend kann über die Annotation `@Gesichert` die Berechtigung zum Zugriff auf die Methode geprüft werden.
Hier werden alle benötigten Rechte des Aufrufers überprüft.
Alternativ kann die Annotation `@Gesichert` auch an der Service-Klasse verwendet werden, wenn alle Methoden die gleiche Autorisierung erfordern.
Die Annotationen sind Bestandteil der T-Komponente Sicherheit (siehe <<NutzungsvorgabenSicherheit>>).

Das Mapping im Beispiel wird durch einen Bean Mapper umgesetzt.
Vor dem Aufruf werden die Parameter gemappt (Klasse `BeispielHolenAnfrageTo` auf Klasse `BeispielHolenAnfrage`),
nach dem Aufruf der Rückgabewert (Klasse `BeispielHolenAntwort` auf Klasse `BeispielHolenAntwortTo`).

Die Komponente Service-Logik wird durch eine entsprechende Spring-Konfigurationsklasse verschaltet.

:desc-listing-BSPServiceFassade: Beispiel für eine Service-Fassade
[id="listing-BSPServiceFassade",reftext="{listing-caption} {counter:listings }"]
.{desc-listing-BSPServiceFassade}
[source,java]
----
public class BeispielServiceFassade {
    private static final IsyLoggerStandard logger = ...;

    private MapperFacade beanMapper;
    private Beispiel beispiel;

    @StelltAufrufKontextBereit
    @Gesichert(Rechte.RECHT_ZUGRIFFBEISPIEL)
    public BeispielHolenAntwortTo holeBeispielAnfrage(AufrufKontextTo kontext, BeispielHolenAnfrageTo anfrage) {

        try {
            BeispielHolenAnfrage anfrageAwk = beanMapper.map(anfrage, BeispielHolenAnfrage.class);
            BeispielHolenAntwort antwortAwk = beispiel.holeBeispielAnfrage(anfrageAwk);

            return beanMapper.map(antwortAwk, BeispielHolenAntwortTo.class);
        } catch (MappingException e) {
            logger.error("...", e);
            throw new TechnicalException(...);
        }
	...
}
----

==== Transaktionssteuerung

In der Regel geschieht die Transaktionssteuerung im Anwendungskern.
Gibt es allerdings Anforderungen, aus denen heraus die Service-Fassade eine Transaktion über mehrere Aufrufe des Anwendungskerns hinweg bilden muss, so muss diese Transaktion über die Service-Fassade gesteuert werden.
Die Aufgabe fällt der Service-Fassade zu, weil es wichtig ist, dass die Fehlerbehandlung auf jeden Fall die Transaktion umschließt.
Nur so ist gewährleistet, dass auch Fehler, die beim Commit entstehen, von der Fehlerbehandlung erfasst werden.

Die Transaktionssteuerung wird an der jeweiligen Service-Methode angesetzt.
Für das obige Beispiel verdeutlicht dies <<listing-service-fassade-tx>>.

:desc-listing-service-fassade-tx: Transaktionssteuerung in der Service-Fassade
[id="listing-service-fassade-tx",reftext="{listing-caption} {counter:listings }"]
.{desc-listing-service-fassade-tx}
[source,java]
----
public class BeispielServiceFassade {
    ...
    @StelltAufrufKontextBereit
    @Gesichert(Rechte.RECHT_ZUGRIFFBEISPIEL)
    @Transactional(rollbackFor = Throwable.class, propagation = Propagation.REQUIRED)
    public BeispielHolenAntwortTo holeBeispielAnfrage(
        AufrufKontextTo kontext, BeispielHolenAnfrageTo anfrage)
        throws BeispielException {
        ...
    }
    ...
}
----

Eine Sonderstellung nehmen Services ein, die im Fehlerfall keinen Fehler zurückgeben, sondern die Fehler in der Antwortnachricht übermitteln.
Der AOP-Transaktionsmanager wird niemals ein Rollback durchführen, da alle Exceptions abgefangen werden, auf die er reagieren könnte.
Um auch in diesem Fall ein Rollback der Transaktion zu erzwingen, ist folgender Aufruf durchzuführen:

:desc-listing-service-fassade-tx-rollback-only: Rollback von Transaktionen im Fehlerfall ohne Exceptions
[id="listing-service-fassade-tx-rollback-only",reftext="{listing-caption} {counter:listings }"]
.{desc-listing-service-fassade-tx-rollback-only}
[source,java]
----
TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();
----


[[realisierung]]
== Realisierung einer Service-Schnittstelle

Service-Gateway (d.h. Service-Consumer oder Service-Provider) und IT-Systeme teilen sich die Java-Klassen der
RemoteBean-Schnittstelle:

* Java-Interface der RemoteBean
* Transport-Objekte
* Exceptions

Bei Transport-Objekten ist zu beachten, dass die UID stets 0 ist:

[source,java]
----
public class BeispielTransportObjekt {
    private static final long serialVersionUID = 0L;
}
----

Die Schnittstelle wird in der Regel in einer älteren Java-Version kompiliert, als die Anwendung kompiliert ist, um die Schnittstelle auch in älteren Anwendungen einsetzen zu können.
Wenn die Schnittstelle jedoch ausschließlich von einem Service Gateway bzw. einer Fachanwendung genutzt wird, welche die aktuelle Java-Version einsetzen, kann auch die Schnittstelle in der aktuellen Java-Version kompiliert werden.

[[nutzung]]
== Nutzung einer Service-Schnittstelle

Zur Nutzung einer entfernten Schnittstelle bindet ein Anwendungssystem das erstellte Schnittstellen-JAR ein und
initialisiert die RemoteBeans damit.

Das geschieht über die vom Spring Framework bereitgestellte Factory-Klasse `HttpInvokerProxyFactoryBean`, wie in <<listing-invokerconfig>> dargestellt.
Auf dieser Bean können dann die entfernten Methoden aufgerufen werden.

:desc-listing-invokerconfig: Konfiguration für die Nutzung einer entfernten Schnittstelle
[id="listing-invokerconfig",reftext="{listing-caption} {counter:listings }"]
.{desc-listing-invokerconfig}
[source,java]
----
@Configuration
public class ServiceConfiguration {

    @Bean
    public HttpInvokerProxyFactoryBean virenscanRemoteBean(HttpInvokerRequestExecutor executor, ServiceConfigProperties config) {
        HttpInvokerProxyFactoryBean invoker = new HttpInvokerProxyFactoryBean();
        invoker.setServiceUrl(config.getServiceUrl());
        invoker.setServiceInterface(VirenscanRemoteBean.class);
        invoker.setHttpInvokerRequestExecutor(executor);
        return invoker;
    }

    @Bean
    public TimeoutWiederholungHttpInvokerRequestExecutor executor(ServiceConfigProperties config) {
        TimeoutWiederholungHttpInvokerRequestExecutor executor = new TimeoutWiederholungHttpInvokerRequestExecutor();
        executor.setAnzahlWiederholungen(config.getWiederholungen());
        executor.setTimeout(config.getTimeout());
        return executor;
    }

----

Die FactoryBean erwartet eine Service-URL und ein Interface zur Initialisierung.
Der Host-Teil der URL muss in jedem Fall in der betrieblichen Konfiguration der Anwendung zu finden sein.
Das Interface ist im Schnittstellen-JAR verfügbar.

Die Nutzung des hier im Beispiel verwendeten `TimeoutWiederholungHttpInvokerRequestExecutor` ist optional.
Dieser Executor bricht nach dem angegebenen Timeout die Anfrage ab und wiederholt sie bis zur maximalen angegebenen
Wiederholungsanzahl.

Wenn die Anwendung isy-logging (<<NutzungsvorgabenLogging>>) nutzt, muss statt der Spring-eigenen Factory die erweiterte `IsyHttpInvokerProxyFactoryBean` genutzt werden.
Sie versieht die RemoteBeans automatisch mit einem `LogMethodInterceptor`, der die Aufrufzeiten der ausgehenden Aufrufe misst und loggt.
Die Konfiguration erfolgt wie in <<listing-isyinvokerconfig>> gezeigt:

:desc-listing-isyinvokerconfig: Konfiguration mit IsyHttpInvokerProxyFactoryBean
[id="listing-isyinvokerconfig",reftext="{listing-caption} {counter:listings }"]
.{desc-listing-isyinvokerconfig}
[source,java]
----
@Bean
public IsyHttpInvokerProxyFactoryBean virenscanRemoteBean(HttpInvokerRequestExecutor executor, ServiceConfigProperties config) {
    IsyHttpInvokerProxyFactoryBean invoker = new IsyHttpInvokerProxyFactoryBean();
    invoker.setServiceUrl(config.getServiceUrl());
    invoker.setServiceInterface(VirenscanRemoteBean.class);
    invoker.setHttpInvokerRequestExecutor(executor);
    invoker.setRemoteSystemName(config.getRemoteSystemName());
    return invoker;
}
----

Die erweiterte ProxyFactoryBean erwartet nur einen zusätzlichen Parameter `remoteSystemName`.
Dieser wird genutzt, um einen sprechenden Systemnamen bei den Log-Ausgaben auszugeben.


[[versionierung]]
== Versionierung

Die Notwendigkeit, Services in mehreren Versionen anbieten zu können, ist bedingt durch die Vielzahl an Service-Nutzern, die bei Änderung an einem Service nicht alle zeitgleich auf die neue Version eines Service umschalten können.
Daher ist es notwendig, dass in einem - möglichst klein zu haltenden - Übergangszeitraum mehrere Versionen eines Service parallel betrieben werden können.

Die Versionierung wird auf der Ebene von Services, nicht Service-Operationen ausgeführt, da diese Ebene von ihrer Granularität zu den üblichen fachlichen Änderungen passt.

NOTE: Für die HTTP-Invoker-Schnittstelle heißt das, dass die komplette RemoteBean-Schnittstelle versioniert wird und nicht die einzelnen Methoden der RemoteBean-Schnittstelle.

Es kann vorkommen, dass in _einem_ Systemrelease neue Versionen von _mehreren_ Services ausgeliefert werden.

[[architektur]]
=== Architektur

IT-Systeme bieten pro Service-Version eine eigene Service-Schnittstelle an.
Die Services verwenden alle denselben <<glossar-Anwendungskern>>.
Die für die Versionierung notwendigen Transformationen sind Teil der jeweiligen Service-Schnittstelle (z.B. das Einfügen eines Standardwerts für neu hinzugefügte Attribute).
In komplexen Fällen kann es auch notwendig sein, den Anwendungskern zu erweitern und die Versionierung dort zu behandeln.
Die Entscheidung dafür ist im Systementwurf zu dokumentieren.

Externe Services werden durch Service-Gateways bereitgestellt.
Die Versionierung eines Services muss also auch auf Ebene des Service-Gateways durchgeführt werden.
Ein Service-Gateway ist ein rein technischer Protokoll-Wandler, der Web-Services in interne Schnittstellen konvertiert.
Im Service-Gateway erfolgt daher immer nur ein einfaches Mapping auf die entsprechenden Service-Schnittstellen der angebundenen IT-Systeme.
Der Ausgleich der Versionsunterschiede erfolgt ausschließlich im IT-Systeme und nicht im Service-Gateway.
Es ist möglich, pro Service-Version ein eigenes Service-Gateway zu erstellen (siehe <<image-archversServ>>).

:desc-image-archversServ: Architektur versionierter Services
[id="image-archversServ",reftext="{figure-caption} {counter:figures}"]
.{desc-image-archversServ}
image::archversServ.png[align="center",width=60%,pdfwidth=60%]

[[einfachster-fall-kompatible-erweiterung-eines-services]]
=== Einfacher Fall: Kompatible Erweiterung eines Services

Ein IT-System stellt einen Service bereit, mit dem Personendaten gemeldet werden können.
Parameter dieser Meldung sind Vor- und Nachname sowie das Geburtsdatum.
Dazu gibt es einen Meldung-Service in der Version 1.0. Dieser wird in der Service-Schicht des IT-Systems implementiert.
Ab einem Stichtag soll zusätzlich noch das Geschlecht gemeldet werden.
Im bisherigen Datenbestand wird dieses neue Attribut auf den Wert „unbekannt“ gesetzt.
Der bestehende Service wird um dieses Attribut erweitert und erhält die Versionsnummer 1.1. Anwendungskern und Datenzugriffsschicht müssen ebenfalls erweitert werden.
Aus Gründen der Rückwärtskompatibilität soll aber weiterhin die Version 1.0 des Service angeboten werden.
Dazu wird ein neuer Service innerhalb der Service-Schicht implementiert, der die Meldung entgegennimmt, das fehlende Attribut mit dem Wert „unbekannt“ ergänzt und dann den Anwendungskern aufruft.

Werden die beiden Services durch ein Service-Gateway nach außen verfügbar gemacht, existieren dort zwei parallele Mappings auf die jeweiligen Services des IT-Systems.
Innerhalb des Service Gateways existiert keine Geschäftslogik, d.h. die Abbildung von Version 1.0 auf 1.1 findet erst im IT-System statt.

[[komplexerer-fall-inkompatible-veraenderung-eines-services]]
=== Komplexerer Fall: Inkompatible Veränderung eines Services

In einem komplexeren Fall kann es passieren, dass die Service-Schnittstelle einer Anwendung komplett umgestaltet wird, sodass die Aufrufe nicht mehr einfach aufeinander abgebildet werden können.
Wird in so einem Fall ein neuer Service eingeführt, während der alte Service noch verfügbar bleiben muss, müssen die inkompatiblen Verarbeitungslogiken im Anwendungskern parallel erhalten bleiben.
Auch hier enthält der Service-Gateway keine Geschäftslogik.

=== Umsetzung
Die Java-Klassen und -Interfaces eines Services existieren in allen Versionen der Service-Schnittstelle und unterscheiden sich inhaltlich
durch die in der neuen Version durchgeführten Änderungen.

NOTE: Für die Versionierung von Schnittstellen gelten gesonderte Vorgaben, die in <<IsyFactVersionierung>> definiert sind.

Zur Veröffentlichung von API-kompatiblen Änderungen wird im Maven `pom.xml` eine einstellige Versionsnummer (Minor) gesetzt.
Kompatible Änderungen sind beispielsweise Bugfixes, neue Operationen in der Schnittstelle oder neue, optionale Attribute im Datenmodell.

:desc-listing-versioning-pom: Realisierung der Versionierungsvorgaben für Schnittstellen bei HTTP-Invoker.
[id="listing-versioning-pom", reftext="reftext="{listing-caption} {counter:listings }"]
.{desc-listing-versioning-pom}
[source,xml]
----
<dependencies>
    ...
    <dependency>
        <groupId>${Organisation.Domäne.Anwendungsname}</groupId>
        <artifactId>${Anwendungsname}-${Schnittstellentechnologie}-sst-${Servicename}-v${Major-Version}</artifactId>
        <version>${Minor-Version}</version>
    </dependency>
    ...
</dependencies>
----

Bei inkompatiblen Änderungen der Schnittstelle wird die zweistellige Versionsnummer angepasst (Major und Minor); diese wird sowohl in der Artefakt-ID als auch in den Paketnamen der Schnittstelle verwendet.
Inkompatible Änderungen der Schnittstelle sind z.B. das Entfernen von Attributen oder Operationen oder das Hinzufügen von Pflichtfeldern.

Bei der Implementierung ist zu beachten, dass die Versionsnummer aus dem Package-Namen auch in die Implementierung übernommen wird.

[[grenzen]]
=== Grenzen

Eine Versionierung ist nur dann sinnvoll, wenn kleine Änderungen an der Schnittstelle zwischen den Versionen auftreten.
Für den Fall, dass sich die Schnittstelle sowohl syntaktisch als auch semantisch grundlegend ändert, sollte anstatt einer neuen Version besser eine eigenständige, neue Schnittstelle entstehen.


[[verfuegbarkeit]]
== Verfügbarkeit

Die IsyFact berücksichtigt die folgenden Anforderungen an die Verfügbarkeit von Services in Systemlandschaften.

*Hohe Verfügbarkeit:* Die IT-Systeme der Systemlandschaft müssen eine hohe Verfügbarkeit aufweisen.
Die Berechnung der Verfügbarkeit einer Anwendung ist komplex.
In die Berechnung fließen unter anderem betriebliche Aspekte wie Hardwareverfügbarkeit ein, während Wartungsfenster herausgerechnet werden.
Weiter könnte man Verfügbarkeit auf der Ebene von angebotenen Services und nicht von IT-Systemen betrachten.
Von der Seite der Software ist zu beachten, dass sich in einer serviceorientierten Systemlandschaft die Ausfallwahrscheinlichkeiten multiplizieren, wenn Systeme einander aufrufen.

*Schnelles Antwortzeitverhalten im Fehlerfall:* Die Nichtverfügbarkeit von Services ist ein Ausnahmefall, auf den angemessen reagiert werden muss.
Sollte ein Service nicht verfügbar sein, ist es wichtig, dass die aufrufende Anwendung zügig eine Fehlermeldung erhält.
Speziell bei Online-Anwendungen ist der schnelle Erhalt einer Fehlermeldung notwendig.
Der Nutzer soll auch im Fehlerfall eine gewohnt schnelle Antwort vom System erhalten.
Die genaue Definition des Zeitrahmens, in dem die Fehlermeldung über die Nichtverfügbarkeit beim Aufrufer eintreffen muss, ist anwendungsspezifisch.
Die Definition ist dementsprechend durch die jeweiligen Aufrufer vorzunehmen.

=== Beispielszenario

Für das Szenario gehen wir im Folgenden davon aus, dass ein IT-System eine Gesamtverfügbarkeit von 98 % aufweisen soll.
Hierbei ist zu beachten, dass IT-Systeme in der Regel andere IT-Systeme und Querschnittssysteme aufrufen, um Anfragen zu beantworten.
Die Gesamtverfügbarkeit sinkt dadurch ab, da zur erfolgreichen Bearbeitung einer Anfrage alle Systeme zeitgleich verfügbar sein müssen.
Im Szenario wird für alle Systeme ein Richtwert für die Verfügbarkeit von 99,7 % angenommen.
<<table-GMTMT>> zeigt eine Beispielrechnung (die Gesamtverfügbarkeit ergibt sich aus dem Produkt der Einzelverfügbarkeiten).
Durch eine Verfügbarkeit von 99,7 % pro System kann im Beispiel also eine Gesamtverfügbarkeit von über 98 % erreicht werden.

Eine Berechnung der Gesamtverfügbarkeit nach dem Schema von <<table-GMTMT>> muss für jedes IT-System einzeln durchgeführt werden.
Dabei müssen die berechneten oder gemessenen Verfügbarkeiten aller IT-Systeme zugrunde gelegt werden, die das IT-System aufruft.

:desc-table-GMTMT: Beispielrechnung der Verfügbarkeit
[id="table-GMTMT",reftext="{table-caption} {counter:tables}"]
.{desc-table-GMTMT}
[cols=",",options="header"]
|====
|System |Verfügbarkeit
|IT-System |99,7 %
|Aufgerufenes IT-System 1 |99,7 %
|Aufgerufenes IT-System 2 |99,7 %
|Aufgerufenes Querschnittssystem |99,7 %
|Service-Gateway (Infrastruktur) |99,7 %
|Datenbank (Infrastruktur) |99,7 %
|*Gesamtverfügbarkeit* |(99,7 %)^6^ = *98,21 %*
|====

[[ursachen-fuer-nichtverfuegbarkeit]]
=== Ursachen für Nichtverfügbarkeit

Die möglichen Ursachen für Nichtverfügbarkeit sind unter anderem:

[[ausfall-deployment]]
*Deployment einer Anwendung:* Bei einem Re-Deployment einer Anwendung kommt es zu einer geplanten Auszeit.

*Überlastung während Lastspitzen:* Im Tagesverlauf variiert die Last, die ein System verarbeiten muss.
Manche Systeme antworten bei Lastspitzen zu langsam.

[[ausfall-von-hw-oder-sw]]
*Ausfall von Hard- oder Software:* Auf einem Knoten eines Anwendungsclusters ist eine Störung durch einen Hardware- oder Softwareausfall aufgetreten.
Der nicht funktionierende Knoten ist dadurch temporär nicht verfügbar, wodurch die verbleibenden Knoten die Last des ausgefallenen Knotens mitverarbeiten müssen.

*Umschaltzeit bei Hard- oder Softwareausfall:* Bei Ausfall von Hard- oder Software sorgt ein Loadbalancer dafür, dass alle Anfragen nur an die noch funktionierenden Knoten weitergeleitet werden.
In dem kurzen Zeitraum, bis der Loadbalancer einen Server-Knoten als ausgefallen markiert („Umschaltzeit“), kommt es jedoch zur Nichtverfügbarkeit von Services.
In diesem Zeitraum werden Anfragen nicht beantwortet die noch an den ausgefallenen Knoten geleitet werden.
[NOTE]
====
Die Regeln, nach denen der Loadbalancer entscheidet, wann ein Server-Knoten nicht mehr verfügbar ist, können üblicherweise konfiguriert werden.
Beispielsweise kann ein Loadbalancer alle paar Sekunden per Script („Health-Check“) überprüfen, ob ein Server-Knoten noch verfügbar ist.
Erst nach einer festgelegten Anzahl fehlgeschlagener fachlicher Anfragen und negativem Health-Check leitet dann der Loadbalancer keine Anfragen mehr an diesen Knoten.
Unabhängig von der Konfiguration kann es trotz Loadbalancer und Anwendungscluster zu wenigen nicht beantworteten Anfragen und somit
zu einer Nichtverfügbarkeit kommen.
====

*Batchläufe:* Wenn lang laufende Batches in Fachanwendungen durchgeführt werden, dürfen in dieser Zeit keine Meldungen gemacht werden.
So werden Dateninkonsistenzen vermieden.
Meldungsaufrufe sind in dieser Zeit nicht verfügbar und werden von der Fachanwendung nicht beantwortet.

[[retries-loadbalancer]]
*Retries des Loadbalancers:* Tritt ein Ausfall von Hard- oder Software auf (siehe _Ausfall von Hard- oder Software_ oben), bekommt der Loadbalancer beim Weiterleiten einer Anfrage an einen ausgefallenen Knoten ein Timeout.
Loadbalancer können so konfiguriert werden, dass sie in diesem Fall die gleiche Anfrage an einen noch funktionierenden Knoten weiterleiten und nicht sofort eine Fehlermeldung an den Aufrufer zurückgeben.
Für den Aufrufer hat der Service dadurch eine längere Antwortzeit.
Der Aufrufer hat keine Möglichkeit dieses Timeout/Retry-Verhalten des Loadbalancers zu beeinflussen und auf seine Bedürfnisse anzupassen.
Die lange Antwortzeit kann aufseiten des Aufrufers leicht zu einem Timeout führen.

*Verschlimmerung von Nichtverfügbarkeiten:* Die aufrufende Anwendung reagiert nicht angemessen auf eine Nichtverfügbarkeit eines Service.
Beispiele:

* Der Client versucht Retries, obwohl der Service-Aufruf aus fachlicher Sicht entfallen könnte (optionaler Aufruf).
* Die fachliche Verarbeitung wird nicht rechtzeitig abgebrochen, obwohl ein verpflichtender Service-Aufruf bereits fehlgeschlagen ist.
* Die Bearbeitung der Anfrage dauert bekanntermaßen beim Service-Anbieter sehr lange.
Der Aufrufer hat einen sehr knappen Timeout gesetzt und schickt Aufrufwiederholungen.
Dies verschlimmert die Antwortzeiten der Service-Aufrufe und führt eventuell zu Duplikaten beim Service-Anbieter.

Eine weitere bekannte Ursache für Nichtverfügbarkeit ist die Umgebungskonfiguration, Firewall-Verbindungen nach einer definierten Zeit automatisch zu schließen.
Zustandsbehaftete Verbindungen wie sie bei LDAP- und Datenbank-Clients eingesetzt werden, sind von dieser Restriktion betroffen.
Diese Clients müssen vorsehen, dass Sie eine von der Firewall geschlossene Verbindung erkennen und wieder neu aufbauen.
Dieses Thema wird in den entsprechenden Nutzungskonzepten wie <<DetailkonzeptKomponenteDatenzugriff>> und <<NutzungsvorgabenSpringLDAP>> behandelt.

Die IsyFact setzt als Transportprotokoll für Service-Kommunikation durchgängig HTTP ein.
HTTP ist ein zustandsloses Protokoll und baut bei jeder Anfrage eine neue Verbindung zwischen Client und Server auf.
HTTP 1.1 bietet einen Mechanismus an, mehrere Anfragen über eine TCP-Verbindung zu transportieren.
Wenn eine Schnittstellentechnologie diesen Mechanismus nutzt, müssen die TCP-Verbindungen vor ihrer Verwendung validiert werden.

[[massnahmen]]
=== Maßnahmen

Folgende Maßnahmen können ergriffen werden, um die Anforderungen an die Verfügbarkeit zu gewährleisten.

==== Anwendungscluster mit Loadbalancer

Die TI-Architektur der IsyFact setzt die hohen Verfügbarkeitsanforderungen durch Clustering der Applikations- und Datenbankserver um.
Anwendungen werden redundant auf mehr als einem Server installiert.
Kommt es zu einem <<ausfall-von-hw-oder-sw, Hard- oder Softwareausfall>> auf einem Server-Knoten, so werden alle Anfragen von einem vorgeschalteten Loadbalancer auf einen anderen Server-Knoten umgeleitet.
Durch die Redundanz wird die Verfügbarkeit von Services bei auftretenden Hard- oder Softwareausfällen erhöht.
Trotzdem kann es auch hier noch zu Nichtverfügbarkeit kommen.

==== Knotenweises Deployment

Diese Maßnahme hilft bei Nichtverfügbarkeit aufgrund von <<ausfall-deployment, geplanten Wartungsarbeiten>>.
Im Clusterbetrieb besteht die Möglichkeit, diese Knoten für Knoten auszuführen.
Bevor das Deployment auf einem Knoten ausgeführt wird, wird dem Loadbalancer mitgeteilt, dass der Knoten nicht mehr verfügbar ist.
Während des Deployments des Knotens verarbeiten die restlichen Knoten alle ankommenden Anfragen.
Nach Abschluss des Deployments des Knotens wird dem Loadbalancer mitgeteilt, dass der Knoten wieder zur Verfügung steht.
Dann kann das Deployment des nächsten Knotens nach dem gleichen Schema erfolgen.
Dadurch können Services im Zeitraum von Wartungsarbeiten voll verfügbar gehalten werden.
Dieser „Web-Off-Mechanismus“ wird in <<DeploymentKonzept>> im Detail beschreiben.

==== Time-To-Live

Ein Service-Aufruf ist nur für eine bestimmte Zeit gültig.
Diese Zeitspanne wird als Time-To-Live (TTL) bezeichnet.
Der Aufrufer definiert die TTL und legt so fest, wie lange er bei einem Aufruf auf eine Antwort wartet.
Hierdurch wird eine schnelle Antwortzeit gewährleistet.

==== Aufrufwiederholung (Retry)

Von <<retries-loadbalancer,Loadbalancern ausgeführte Retries>> können zu einer Erhöhung der Antwortzeit führen.
Loadbalancer innerhalb der Plattform sind deshalb so zu konfigurieren, dass fehlgeschlagene Anfragen nicht an andere Knoten weitergeleitet werden.
Eine Wiederholung von Aufrufen ist ausschließlich vom Aufrufer auszuführen.
So kann der Aufrufer je nach Fachlichkeit entscheiden, bei welchen Anfragen Wiederholungen sinnvoll sind.

Grundsätzlich sind Retries nur mit größter Vorsicht anzuwenden!
Hierfür gibt es mehrere Gründe:

Ruft ein Client einen Service auf und erhält einen technischen Fehler, so kann der Client anhand des technischen Fehlers in der Regel nicht einwandfrei erkennen, ob seine Anfrage nicht doch auf dem Server erfolgreich verarbeitet wurde.
Beispielsweise kann durch einen Netzwerkausfall zwar die Netzwerkverbindung zum Server abgebrochen sein, das hindert den Server aber nicht daran, eine bereits in Verarbeitung befindliche Service-Anfrage weiterzuverarbeiten.
In einem solchen Fall würde ein automatischer Retry dazu führen, dass ein und dieselbe Service-Anfrage zweimal ausgeführt würde.
Dies kann bei nicht-idempotenten Service-Operationen fatale Auswirkungen haben (z. B. Löschen von falschen Daten).

Eine automatische Aufrufwiederholung kann im Falle einer echten Nichtverfügbarkeit zu einer erhöhten Netzwerklast führen und so die Nichtverfügbarkeit auch anderer Anwendungen in der Anwendungslandschaft erhöhen.
Die Situation wird daher durch die Aufrufwiederholung deutlich verschlechtert.

Insbesondere bei einem Timeout eines TTL ist jedoch ein Retry mit großer Vorsicht zu genießen, da nicht klar ist, ob die Service-Anfrage nicht doch durch den Server bearbeitet wird.
In einem solchen Fall führt eine Aufrufwiederholung zu einer erhöhten Last auf dem Server und kann im schlechtesten Fall zu einer echten Nichtverfügbarkeit des Services bzw. des kompletten Servers führen.

[TIP]
====
In Anbetracht der potenziellen Probleme der Aufrufwiederholung und der Tatsache, dass eine Aufrufwiederholung nur für idempotente Service-Operationen überhaupt zulässig ist, sollte von einer automatischen Aufrufwiederholung als Maßnahme zur Erhöhung der Verfügbarkeit in der Regel abgesehen werden.

Ausgenommen davon sind Aufrufe, bei denen nur Daten gelesen werden, wie z.B. Suchen im Suchverfahren oder Abfragen von Verzeichnissen wie Schlüsselverzeichnis, Benutzerverzeichnis oder Behördenverzeichnis.

Hierfür soll grundsätzlich eine Aufrufwiederholung durchgeführt werden.
Diese ist sinnvoll über die folgenden Parameter konfigurierbar:

* Pause zwischen den Retries,
* Maximale Anzahl von Retries,
* Timeout für Anfragen.

Die Parameter sind Bestandteil der betrieblichen Konfiguration (s. <<KonzeptKonfiguration>>).
====

==== Deaktivierung von Services

Aufgrund von Wartungsaktivitäten oder Batches (z.B. einer Datenmigration) in einer Fachanwendung kann es vorkommen, dass der Meldungsservice einer Fachanwendung vorübergehend deaktiviert wird.
Andere Services wie z.B. eine Auskunft können während dieser Zeit regulär ausgeführt werden.
Während der Meldungsservice deaktiviert ist, wird dem Aufrufer eine entsprechende Fehlermeldung zurückgesendet.
Da die Anforderung besteht, auch andere Services vorübergehend deaktivieren zu können, werden generell alle Services deaktivierbar gemacht.
// end::inhalt[]